{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspecting Your Data, Part 2: Carpet AMR Data\n",
    "\n",
    "In this notebook, we show how to investigate Einstein Toolkit data in Python. The Einstein Toolkit uses an AMR library, called Carpet. Carpet is a complicated piece of machinery, so let's see if we can understand some of its moving parts as we go along.\n",
    "\n",
    "First, let's import the same python tools as we used before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams.update({'font.size':18})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the files that Carpet output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls qc0-mclachlan-cell-t0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Carpet outputs one hdf5 file per \"variable group\" (or per variable, depending on your settings) per MPI thread. Syou can see that this simulation was run on four MPI threads (though it could be many more openmp threads since Carpet is hybrid-parallelized.) Let's look inside one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('qc0-mclachlan-cell-t0/admbase-lapse.file_0.h5','r')\n",
    "list(f.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the typical format for a Carpet IO file. Let's unpack it:\n",
    "\n",
    "`ADMBASE::alp`\n",
    "means that the variable is named `alp` and is defined in the `ADMBASE` thorn. This is the lapse in the ADM formulation of the Einstein equations.\n",
    "\n",
    "`it=0`\n",
    "means this output is from the zeroth iteration of the simulation. It's initial data.\n",
    "\n",
    "`tl=0` refers to the subcycling in time that Carpet can do. (Finer grids can be evolved at shorter timesteps than coarser grids.) Unless you explicitly ask, Carpet will always output data with `tl=0`. \n",
    "\n",
    "`rl=0` specifies the coarseness of the grid. The grid spacing $\\Delta x$ is divided by a factor of two for each increased refinement level. So `rl=6` has a grid spacing $2^6$ times smaller than `rl=0`. \n",
    "\n",
    "`c=0` specifies the *component* of the grid that Carpet has output. When Carpet distributes the grid structure onto a distributed memory supercomputer, it has to give different pieces of the grid to different MPI threads. Each of these pieces of a grid is called a component. Carpet chooses to output components as it likes to balance the load as best it can. In this example, carpet assigned one component at each refinement level to each MPI thread. This is a typical configuration but *it is not guaranteed.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look in more detail what's inside that `Parameters and Global Attributes` group. A group is a kind of subdirectory in an HDF5 file. It's a way of making the files self-describing. Carpet puts useful metadata in this group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(f['Parameters and Global Attributes'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can probably guess what some of these contain. The `Datasets` dataset just contains a list of variable names the file contains. Ours only contains the lapse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f['Parameters and Global Attributes/Datasets'].value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other datasets in this group are more interesting. `All Parameters` contains what is essentially a copy of the parameter file used to run the simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(f['Parameters and Global Attributes/All Parameters'].value,encoding='utf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the `Grid Structure v5` dataset contains a description of how Carpet structured the AMR hierarchy and broke up the AMR grids into components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(f['Parameters and Global Attributes/Grid Structure v5'].value,encoding='utf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't meant to be human readable---it's a direct dump of the internal represnetation Carpet keeps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close() # make sure to close an hdf5 file when you're done with it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read in the lapse and the grid data. We can read in all the relevant files using the Python glob tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "grid_filenames = sorted(glob('qc0-mclachlan-cell-t0/grid-coordinates.file_*.h5'))\n",
    "lapse_filenames = sorted(glob('qc0-mclachlan-cell-t0/admbase-lapse.file_*.h5'))\n",
    "\n",
    "grid_filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can read in all the relevant components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {}\n",
    "for filename in grid_filenames:\n",
    "    with h5py.File(filename,'r') as f:\n",
    "        for k,v in f.items():\n",
    "            try: # this little trick reads only data sets from the root group\n",
    "                grid[k] = v.value\n",
    "            except:\n",
    "                pass\n",
    "lapse = {}\n",
    "for filename in lapse_filenames:\n",
    "    with h5py.File(filename,'r') as f:\n",
    "        for k,v in f.items():\n",
    "            try: # this little trick reads only data sets from the root group\n",
    "                lapse[k] = v.value\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(grid.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(lapse.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A commom trick I like to use is to define functions to access the various field names. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coord(d, rl, c, it = 0, tl = 0):\n",
    "    return grid['GRID::{} it={} tl={} rl={} c={}'.format(d,it,tl,rl,c)]\n",
    "def get_lapse(rl,c,it=0,tl=0):\n",
    "    return lapse['ADMBASE::alp it={} tl={} rl={} c={}'.format(it,tl,rl,c)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can load in and plot a component. (Note that the index ordering is fortran order. The indices go $zyx$.) For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl = 6\n",
    "c = 3\n",
    "alpha = get_lapse(rl,c)\n",
    "X,Y,Z = [get_coord(d,rl,c) for d in ['x','y','z']]\n",
    "iz = int(Z.shape[2]/2)\n",
    "mesh = plt.pcolormesh(X[iz],Y[iz],alpha[iz],rasterized=True)\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label(r'$\\alpha$')\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$y$')\n",
    "plt.savefig('../figures/lapse2d.pdf',bbox_inches='tight',dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "This simulation data contains two black holes in-spiraling in puncture coordinates. Can you find their coordinate locations? \n",
    "\n",
    "**HINT:** The lapse $\\alpha$ is minimal near the punctures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
